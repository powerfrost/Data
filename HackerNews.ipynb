{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacker News Posts\n",
    "\n",
    "[Hacker News](https://news.ycombinator.com/) is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "`id`: The unique identifier from Hacker News for the post\n",
    "\n",
    "`title`: The title of the post\n",
    "\n",
    "`url`: The URL that the posts links to, if it the post has a URL\n",
    "\n",
    "`num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "\n",
    "`num_comments`: The number of comments that were made on the post\n",
    "\n",
    "`author`: The username of the person who submitted the post\n",
    "\n",
    "`created_at`: The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the HackerNews.csv into a list\n",
    "\n",
    "\n",
    "from csv import reader\n",
    "\n",
    "opened_file = open(\"HN_posts_year_to_Sep_26_2016.csv\", encoding = \"utf8\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# Print the first 5 rows\n",
    "\n",
    "for row in hn[:5]:\n",
    "    print(row)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "# Only run this once\n",
    "# Assign header row to headers variable\n",
    "# Remove header row from hn\n",
    "\n",
    "hn_raw = list(hn)\n",
    "headers = hn_raw[0]\n",
    "hn = hn_raw[1:]\n",
    "\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asks posts number is 9139\n",
      "Asks posts number is 10158\n",
      "Asks posts number is 273822\n"
     ]
    }
   ],
   "source": [
    "# There are three types of posts\n",
    "# 1. Ask HN posts, 2. Show HN posts, and 3. Other posts\n",
    "# We will create three lists to contain these types of posts\n",
    "\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts= []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "# Check the length of each list\n",
    "\n",
    "print(\"Asks posts number is\", len(ask_posts))\n",
    "print(\"Asks posts number is\", len(show_posts))\n",
    "print(\"Asks posts number is\", len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.39\n",
      "5.43\n"
     ]
    }
   ],
   "source": [
    "# Determine if asks posts or show posts receive more comments on average\n",
    "\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    comments = row[4]\n",
    "    comments = int(comments)\n",
    "    total_ask_comments += comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(round(avg_ask_comments,2))\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    comments = row[4]\n",
    "    comments = int(comments)\n",
    "    total_show_comments += comments\n",
    "\n",
    "avg_show_comments = total_show_comments / len(ask_posts)\n",
    "print(round(avg_show_comments,2))\n",
    "\n",
    "# Average ask comments is higher than average show comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 11.12],\n",
       " [1, 7.39],\n",
       " [22, 8.78],\n",
       " [21, 8.67],\n",
       " [19, 7.15],\n",
       " [17, 9.44],\n",
       " [15, 28.63],\n",
       " [14, 9.67],\n",
       " [13, 16.29],\n",
       " [11, 8.94],\n",
       " [10, 10.65],\n",
       " [9, 7.06],\n",
       " [7, 7.0],\n",
       " [3, 7.92],\n",
       " [23, 6.68],\n",
       " [20, 8.73],\n",
       " [16, 7.7],\n",
       " [8, 9.18],\n",
       " [0, 7.55],\n",
       " [18, 7.95],\n",
       " [12, 12.36],\n",
       " [4, 9.68],\n",
       " [6, 6.76],\n",
       " [5, 8.75]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's focus on ask posts since they have higher avg comments\n",
    "# In ask posts, let's find out what time of the day \n",
    "# there are the highest comments\n",
    "\n",
    "\n",
    "# Creating a list to store created_at and comments\n",
    "import datetime as dt\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    comments = row[4]\n",
    "    comments = int(comments)\n",
    "    result_list.append([created_at, comments])\n",
    "\n",
    "# Creating two dictionarys, to hold count, and to hold comments, by hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    hour = row[0]\n",
    "    hour = dt.datetime.strptime(hour, \"%m/%d/%Y %H:%M\")\n",
    "    hour = hour.strftime(\"%H\")\n",
    "    hour = int(hour)\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "\n",
    "# Create a list to store the average number of comments by hour\n",
    "avg_by_hour = []\n",
    "\n",
    "for row in counts_by_hour:\n",
    "    avg_by_hour.append([row, round((comments_by_hour[row] / counts_by_hour[row]),2)])\n",
    "    \n",
    "avg_by_hour\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28.63, 15],\n",
       " [16.29, 13],\n",
       " [12.36, 12],\n",
       " [11.12, 2],\n",
       " [10.65, 10],\n",
       " [9.68, 4],\n",
       " [9.67, 14],\n",
       " [9.44, 17],\n",
       " [9.18, 8],\n",
       " [8.94, 11],\n",
       " [8.78, 22],\n",
       " [8.75, 5],\n",
       " [8.73, 20],\n",
       " [8.67, 21],\n",
       " [7.95, 18],\n",
       " [7.92, 3],\n",
       " [7.7, 16],\n",
       " [7.55, 0],\n",
       " [7.39, 1],\n",
       " [7.15, 19],\n",
       " [7.06, 9],\n",
       " [7.0, 7],\n",
       " [6.76, 6],\n",
       " [6.68, 23]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list to help sort the values\n",
    "\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "\n",
      "\n",
      "15:00: 28.63 average comments per post\n",
      "13:00: 16.29 average comments per post\n",
      "12:00: 12.36 average comments per post\n",
      "02:00: 11.12 average comments per post\n",
      "10:00: 10.65 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "print(\"\\n\")\n",
    "for row in sorted_swap[:5]:\n",
    "    row[1] = str(row[1])\n",
    "    avg_comments = row[0]\n",
    "    time = dt.datetime.strptime(row[1], \"%H\")\n",
    "    time = time.strftime(\"%H:%M\")\n",
    "    template = \"{0}: {1:.2f} average comments per post\"\n",
    "    print(template.format(time, avg_comments))\n",
    "    \n",
    "# Looks like the best time to post for high average comments would be \n",
    "# between 12 pm - 3 pm EST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
